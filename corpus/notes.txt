Ideas on what to improve and do next:

1. DONE Add full body of pages / content types in csv file

2. DONE Better tokenizier and pre-processing.

3. DONE strip html code from text with beautifulsoup4

4. DONE Install phrasemachine

#install pip2.7
curl -O https://bootstrap.pypa.io/get-pip.py
sudo python2.7 get-pip.py
pip2 install phrasemachine

#Or better convert to python3
https://github.com/slanglab/phrasemachine/issues/9
2to3 -w example.py

cd /usr/local/lib/python3.6/site-packages/phrasemachine
2to3 -w *.py

5. when tokenizing with phrasemachine, do it on one sentence at the time and
not over a large text. Otherwise you get too many phrases and false positives 
made up of words from multiple sentences, somehow phrasemachine expects one
sentence only. OR give up with full text and use only title and description.

6. Stemming?

7. If we take only Title, use only document with Title that has at least 5 terms

8. provide SPACY API see https://github.com/jgontrum/spacy-api-docker

9. FEATURE: Semantic Network Viz: textacy.viz.draw_semantic_network 

see two examples: 
based on POS tokens https://github.com/oroszgy/hungarian-text-mining-workshop/blob/master/1_Intro.ipynb which 
based on pagerank https://github.com/bdewilde/pygotham_2016/blob/master/pygotham_2016.ipynb
